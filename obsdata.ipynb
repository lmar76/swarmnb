{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observatory Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"/>\n",
    "\n",
    "## Contents\n",
    "\n",
    "- [Hourly mean values](#obs)\n",
    "    - [Read data from ASCII files](#obs-read-ascii)\n",
    "    - [Convert data to pandas DataFrame](#obs-to-dataframe)\n",
    "    - [Read data from multiple files](#obs-multifiles)\n",
    "- [Minute and second mean values](#obsms)\n",
    "    - [Read data from CDF files](#obsms-read-cdf)\n",
    "    - [Convert data to pandas DataFrame](#obsms-to-dataframe)\n",
    "    - [Read data from multiple files](#obsms-multifiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"obs\" />\n",
    "\n",
    "## Hourly mean values\n",
    "\n",
    "[[TOP]](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repository:\n",
    "- ftp://ftp.nerc-murchison.ac.uk/geomag/Swarm/AUX_OBS/hour/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"obs-read-ascii\" />\n",
    "\n",
    "### Read data from ASCII files\n",
    "\n",
    "[[TOP]](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings and functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python standard library\n",
    "from pathlib import Path\n",
    "\n",
    "# Extra libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# TODO: update the data dir once the files will be available in the shared folder\n",
    "OBS_HOUR_DIR = Path('~/data/AUX_OBS/hour').expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "# OPTIONAL - download data from the FTP server\n",
    "!wget -nv -nc -P ~/data/AUX_OBS/hour ftp://ftp.nerc-murchison.ac.uk/geomag/Swarm/AUX_OBS/hour/SW_OPER_AUX_OBS_2__201[89]*\n",
    "!find ~/data/AUX_OBS -name \"*.ZIP\" | while read f ; do unzip -u $f -d `dirname $f` ; done\n",
    "!find ~/data/AUX_OBS -name \"*.ZIP\" -delete\n",
    "!find ~/data/AUX_OBS -name \"*.HDR\" -delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select one of the AUX_OBS_2_ files (e.g. the first one):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = sorted(OBS_HOUR_DIR.glob('SW_OPER_AUX_OBS_2_*'))[0]\n",
    "\n",
    "test_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read ASCII file and convert data to a `pandas.DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    test_file,\n",
    "    comment='#',\n",
    "    delim_whitespace=True,\n",
    "    names = ['IAGA_code', 'Latitude', 'Longitude', 'Radius', 'yyyy', 'mm', 'dd', 'UT', 'B_N', 'B_E', 'B_C'],\n",
    "    parse_dates={'Timestamp': [4, 5, 6]},\n",
    "    infer_datetime_format=True\n",
    ")\n",
    "df['Timestamp'] = df['Timestamp'] + pd.to_timedelta(df['UT'], 'h')\n",
    "df.drop(columns='UT', inplace=True)\n",
    "df.set_index('Timestamp', inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on `pandas.Dataframe` see: https://pandas.pydata.org/docs/reference/frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: get minimum and maximum dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.min(), df.index.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: get list of observatories (IAGA codes) stored in the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IAGA_code'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"obs-multifiles\" />\n",
    "\n",
    "### Read data from multiple files\n",
    "\n",
    "[[TOP]](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"obsms\" />\n",
    "\n",
    "## Minute and second mean values\n",
    "\n",
    "[[TOP]](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files containing observatory minute and second mean values have CDF format. They can be downloade from:\n",
    "\n",
    "- ftp://ftp.nerc-murchison.ac.uk/geomag/Swarm/AUX_OBS/minute/\n",
    "- ftp://ftp.nerc-murchison.ac.uk/geomag/Swarm/AUX_OBS/second/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"obsms-read-cdf\" />\n",
    "\n",
    "### Read data from CDF files\n",
    "\n",
    "[[TOP]](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings and functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python standard library\n",
    "import re\n",
    "from contextlib import closing\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Extra libraries\n",
    "import cdflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# TODO: update the data dir once the files will be available in the shared folder\n",
    "OBS_MINUTE_DIR = Path('~/data/AUX_OBS/minute').expanduser()\n",
    "OBS_SECOND_DIR = Path('~/data/AUX_OBS/second').expanduser()\n",
    "\n",
    "\n",
    "def cdf_to_pandas(path, start_date=None, end_date=None):\n",
    "    \"\"\"Convert CDF files found at `path` to a pandas dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str or os.PathLike\n",
    "        path of the directory containing the CDF files (AUX_OBSM2_ or AUX_OBSS2_).\n",
    "    start_date : str or datetime.datetime or numpy.datetime64\n",
    "        lower bound of the selection time window (default ``None``).\n",
    "    end_date : str or datetime.datetime or numpy.datetime64\n",
    "        upper bound of the selection time window (default ``None``).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple(list(pathlib.Path), pandas.DataFrame)\n",
    "        list of source files and observatory data\n",
    "\n",
    "    \"\"\"\n",
    "    PATTERN = re.compile(\n",
    "        r'SW_OPER_AUX_OBS[MS]2__(?P<start>\\d{8}T\\d{6})_(?P<stop>\\d{8}T\\d{6})_'\n",
    "        r'\\d{4}\\.(cdf|DBL)$'\n",
    "    )\n",
    "    MIN_DATE = np.datetime64('0000', 'us')\n",
    "    MAX_DATE = np.datetime64('9999', 'us')\n",
    "    path = Path(path)\n",
    "    start_date = MIN_DATE if start_date is None else np.datetime64(start_date, 'us')\n",
    "    end_date = MAX_DATE if end_date is None else np.datetime64(end_date, 'us')\n",
    "    sources = []\n",
    "    frames = []\n",
    "    for file in (f for f in path.iterdir() if f.is_file()):\n",
    "        match = PATTERN.match(file.name)\n",
    "        if match:\n",
    "            start, stop = match.groupdict().values()\n",
    "            start = np.datetime64(datetime.strptime(start, '%Y%m%dT%H%M%S'), 's')\n",
    "            stop = np.datetime64(datetime.strptime(stop, '%Y%m%dT%H%M%S'), 's')\n",
    "            if end_date >= start and start_date <= stop:\n",
    "                sources.append(file)\n",
    "                with closing(cdflib.cdfread.CDF(file)) as data:\n",
    "                    ts = pd.DatetimeIndex(\n",
    "                        cdflib.cdfepoch.encode(data.varget('Timestamp'), iso_8601=True),\n",
    "                        name='Timestamp'\n",
    "                    )\n",
    "                    df = pd.DataFrame(\n",
    "                        {\n",
    "                            'IAGA_code': data.varget('IAGA_code')[:,0,0],\n",
    "                            'Latitude': data.varget('Latitude'),\n",
    "                            'Longitude': data.varget('Longitude'),\n",
    "                            'Radius': data.varget('Radius'),\n",
    "                            'B_N': data.varget('B_NEC')[:,0],\n",
    "                            'B_E': data.varget('B_NEC')[:,1],\n",
    "                            'B_C': data.varget('B_NEC')[:,2]\n",
    "                        },\n",
    "                        index=ts\n",
    "                    )\n",
    "                    frames.append(df[(df.index >= start_date) & (df.index <= end_date)])\n",
    "    return sorted(sources), pd.concat(frames).sort_values(by=['IAGA_code', 'Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "# OPTIONAL - download data from the FTP server\n",
    "!wget -nv -nc -P ~/data/AUX_OBS/minute ftp://ftp.nerc-murchison.ac.uk/geomag/Swarm/AUX_OBS/minute/SW_OPER_AUX_OBSM2__201912*\n",
    "!wget -nv -nc -P ~/data/AUX_OBS/second ftp://ftp.nerc-murchison.ac.uk/geomag/Swarm/AUX_OBS/second/SW_OPER_AUX_OBSS2__201912*\n",
    "!find ~/data/AUX_OBS -name \"*.ZIP\" | while read f ; do unzip -u $f -d `dirname $f` ; done\n",
    "!find ~/data/AUX_OBS -name \"*.ZIP\" -delete\n",
    "!find ~/data/AUX_OBS -name \"*.HDR\" -delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select one of the AUX_OBSM2_ files (e.g. the first one):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = sorted(OBS_MINUTE_DIR.glob('SW_OPER_AUX_OBSM2_*.DBL'))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CDF file using `cdflib` (for more information on `cdflib`, see: https://github.com/MAVENSDC/cdflib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cdflib.CDF(file1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get info about the file as a Python dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cdf_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that measurements are stored as *zVariables*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cdf_info()['zVariables']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be retrieved via the `.varget()` method, e.g:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.varget('B_NEC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is returned as a `numpy.ndarray` object (for more information on `numpy.ndarray`, see: https://docs.scipy.org/doc/numpy/reference/arrays.ndarray.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable attributes can be retrieved using the `.varattsget()` method, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.varattsget('B_NEC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes are returned as a Python dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrieve the timestamps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.varget('Timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Timestamp` type is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.varget('Timestamp').dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestamps are represented as NumPy `float64` values. Why? Get info about `Timestamp` variable using the `.varinq()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.varinq('Timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned dictionary shows that the data type is *CDF_EPOCH* consising in a floating point value representing the number of milliseconds since 01-Jan-0000 00:00:00.000. It can be converted to a more readable format (list of strings) using the `cdflib.cdfepoch.encode()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = cdflib.cdfepoch.encode(data.varget('Timestamp'), iso_8601=True)\n",
    "\n",
    "ts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or to a numpy array of `numpy.datetime64` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.array(cdflib.cdfepoch.encode(data.varget('Timestamp'), iso_8601=True), dtype='datetime64')\n",
    "\n",
    "ts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be interested also in the CDF global attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.globalattsget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close the file when you have finished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUX_OBSS2_ data contains the same variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with closing(cdflib.cdfread.CDF(list(OBS_SECOND_DIR.glob('SW_OPER_AUX_OBSS2_*.DBL'))[0])) as data:\n",
    "    zvariables = data.cdf_info()['zVariables']\n",
    "\n",
    "zvariables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"obsms-to-dataframe\" />\n",
    "\n",
    "### Convert data to pandas DataFrame\n",
    "\n",
    "[[TOP]](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be represented as a `pandas.DataFrame` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with closing(cdflib.cdfread.CDF(file1)) as data:\n",
    "    ts = np.array(cdflib.cdfepoch.encode(data.varget('Timestamp'), iso_8601=True), dtype='datetime64')\n",
    "    df1 = pd.DataFrame(\n",
    "        {\n",
    "            'IAGA_code': data.varget('IAGA_code')[:,0,0],\n",
    "            'Latitude': data.varget('Latitude'),\n",
    "            'Longitude': data.varget('Longitude'),\n",
    "            'Radius': data.varget('Radius'),\n",
    "            'B_N': data.varget('B_NEC')[:,0],\n",
    "            'B_E': data.varget('B_NEC')[:,1],\n",
    "            'B_C': data.varget('B_NEC')[:,2]\n",
    "        },\n",
    "        index=ts\n",
    "    )\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on `pandas.Dataframe` see: https://pandas.pydata.org/docs/reference/frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: get minimum and maximum dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.index.min(), df1.index.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: get list of observatories (IAGA codes) stored in the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['IAGA_code'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: get list of observatories (IAGA codes) included in the following ranges of coordinates:\n",
    "- $30 \\leq Latitude \\leq 70$\n",
    "- $-10 \\leq Longitude \\leq 40$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[(df1['Latitude'] >= 30) & (df1['Latitude'] <= 70) & (df1['Longitude'] >= -10) & (df1['Longitude'] <= 40)]['IAGA_code'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do the same using the `.query()` method (see: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html#pandas.DataFrame.query):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.query('(30 <= Latitude <= 70) and (-10 <= Longitude <= 40)')['IAGA_code'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"obsms-multifiles\" />\n",
    "\n",
    "### Read data from multiple files\n",
    "\n",
    "[[TOP]](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas dataframes can be concatenated to represent data from more than one file. E.g. read data from the next AUX_OBSM2_ file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = sorted(OBS_MINUTE_DIR.glob('SW_OPER_AUX_OBSM2_*.DBL'))[1]\n",
    "\n",
    "with closing(cdflib.cdfread.CDF(file2)) as data:\n",
    "    ts = np.array(cdflib.cdfepoch.encode(data.varget('Timestamp'), iso_8601=True), dtype='datetime64')\n",
    "    df2 = pd.DataFrame(\n",
    "        {\n",
    "            'IAGA_code': data.varget('IAGA_code')[:,0,0],\n",
    "            'Latitude': data.varget('Latitude'),\n",
    "            'Longitude': data.varget('Longitude'),\n",
    "            'Radius': data.varget('Radius'),\n",
    "            'B_N': data.varget('B_NEC')[:,0],\n",
    "            'B_E': data.varget('B_NEC')[:,1],\n",
    "            'B_C': data.varget('B_NEC')[:,2]\n",
    "        },\n",
    "        index=ts\n",
    "    )\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two dataframes can be concatenated using the `pandas.concat()` function (for more information see: https://pandas.pydata.org/docs/reference/api/pandas.concat.html#pandas.concat):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated = pd.concat([df1, df2])\n",
    "concatenated.index.names = ['Timestamp']\n",
    "concatenated.sort_values(by=['IAGA_code', 'Timestamp'], inplace=True)\n",
    "\n",
    "concatenated.index.min(), concatenated.index.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `cdf_to_pandas()` function defined above to read data from multiple files. E.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources, df = cdf_to_pandas(OBS_MINUTE_DIR, '2019-12-01', '2019-12-02T23:59:59')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With AUX_OBSS2_ data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources, df = cdf_to_pandas(OBS_SECOND_DIR, '2019-12-01', '2019-12-02T23:59:59')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
