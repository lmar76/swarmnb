{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observatory Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"/>\n",
    "\n",
    "## Contents\n",
    "\n",
    "- [Settings and functions](#settings)\n",
    "- [Hourly mean values](#obs)\n",
    "    - [Read data from ASCII files](#obs-read-ascii)\n",
    "    - [Read data from multiple files](#obs-multifiles)\n",
    "- [Minute and second mean values](#obsms)\n",
    "    - [Read data from CDF files](#obsms-read-cdf)\n",
    "    - [Read data from multiple files](#obsms-multifiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"settings\" />\n",
    "\n",
    "## Settings and functions\n",
    "\n",
    "[[TOP]](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python standard library\n",
    "import re\n",
    "from contextlib import closing\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Extra libraries\n",
    "import cdflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# TODO: update the data dir once the files will be available in the shared folder\n",
    "OBS_HOUR_DIR = Path('~/data/AUX_OBS/hour').expanduser()\n",
    "OBS_MINUTE_DIR = Path('~/data/AUX_OBS/minute').expanduser()\n",
    "OBS_SECOND_DIR = Path('~/data/AUX_OBS/second').expanduser()\n",
    "\n",
    "\n",
    "def ascii_to_pandas(file):\n",
    "    \"\"\"Convert an OBS ASCII file to a pandas DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file : str or os.PathLike\n",
    "        OBS ASCII file.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        data contained in the OBS ASCII file.\n",
    "\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\n",
    "        file,\n",
    "        comment='#',\n",
    "        delim_whitespace=True,\n",
    "        names = ['IAGA_code', 'Latitude', 'Longitude', 'Radius',\n",
    "                 'yyyy', 'mm', 'dd', 'UT', 'B_N', 'B_E', 'B_C'],\n",
    "        parse_dates={'Timestamp': [4, 5, 6]},\n",
    "        infer_datetime_format=True\n",
    "    )\n",
    "    df['Timestamp'] = df['Timestamp'] + pd.to_timedelta(df['UT'], 'h')\n",
    "    df.drop(columns='UT', inplace=True)\n",
    "    df.set_index('Timestamp', inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def cdf_to_pandas(file):\n",
    "    \"\"\"Convert an OBS CDF file to a pandas DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file : str or os.PathLike\n",
    "        OBS CDF file.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        data contained in the OBS CDF file.\n",
    "\n",
    "    \"\"\"\n",
    "    with closing(cdflib.cdfread.CDF(file)) as data:\n",
    "        ts = pd.DatetimeIndex(\n",
    "            cdflib.cdfepoch.encode(data.varget('Timestamp'), iso_8601=True),\n",
    "            name='Timestamp'\n",
    "        )\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                'IAGA_code': data.varget('IAGA_code')[:,0,0],\n",
    "                'Latitude': data.varget('Latitude'),\n",
    "                'Longitude': data.varget('Longitude'),\n",
    "                'Radius': data.varget('Radius'),\n",
    "                'B_N': data.varget('B_NEC')[:,0],\n",
    "                'B_E': data.varget('B_NEC')[:,1],\n",
    "                'B_C': data.varget('B_NEC')[:,2]\n",
    "            },\n",
    "            index=ts\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"obs\" />\n",
    "\n",
    "## Hourly mean values\n",
    "\n",
    "[[TOP]](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repository:\n",
    "- ftp://ftp.nerc-murchison.ac.uk/geomag/Swarm/AUX_OBS/hour/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"obs-read-ascii\" />\n",
    "\n",
    "### Read data from ASCII files\n",
    "\n",
    "[[TOP]](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "# OPTIONAL - download data from the FTP server\n",
    "!wget -nv -nc -P ~/data/AUX_OBS/hour ftp://ftp.nerc-murchison.ac.uk/geomag/Swarm/AUX_OBS/hour/SW_OPER_AUX_OBS_2__201[89]*\n",
    "!find ~/data/AUX_OBS -name \"*.ZIP\" | while read f ; do unzip -u $f -d `dirname $f` ; done\n",
    "!find ~/data/AUX_OBS -name \"*.ZIP\" -delete\n",
    "!find ~/data/AUX_OBS -name \"*.HDR\" -delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select one of the AUX_OBS_2_ files (e.g. the first one):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = sorted(OBS_HOUR_DIR.glob('SW_OPER_AUX_OBS_2_*'))[0]\n",
    "\n",
    "file1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read ASCII file and convert data to a `pandas.DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\n",
    "    file1,\n",
    "    comment='#',\n",
    "    delim_whitespace=True,\n",
    "    names = ['IAGA_code', 'Latitude', 'Longitude',\n",
    "             'Radius', 'yyyy', 'mm', 'dd', 'UT', 'B_N', 'B_E', 'B_C'],\n",
    "    parse_dates={'Timestamp': [4, 5, 6]},\n",
    "    infer_datetime_format=True\n",
    ")\n",
    "df1['Timestamp'] = df1['Timestamp'] + pd.to_timedelta(df1['UT'], 'h')\n",
    "df1.drop(columns='UT', inplace=True)\n",
    "df1.set_index('Timestamp', inplace=True)\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on `pandas.Dataframe` see: https://pandas.pydata.org/docs/reference/frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same result can be obtained with the `ascii_to_pandas()` function defined above (see [Settings and functions](#settings))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = ascii_to_pandas(file1)\n",
    "\n",
    "new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the two data frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.testing.assert_frame_equal(df1, new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: get minimum and maximum dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.index.min(), df1.index.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: get list of observatories (IAGA codes) stored in the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['IAGA_code'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"obs-multifiles\" />\n",
    "\n",
    "### Read data from multiple files\n",
    "\n",
    "[[TOP]](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas dataframes can be concatenated to represent data obtained from more than one file. E.g. read data from the next AUX_OBS_2_ file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = sorted(OBS_HOUR_DIR.glob('SW_OPER_AUX_OBS_2_*.txt'))[1]\n",
    "\n",
    "df2 = ascii_to_pandas(file2)\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two dataframes can be concatenated using the `pandas.concat()` function (for more information see: https://pandas.pydata.org/docs/reference/api/pandas.concat.html#pandas.concat):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated = pd.concat([df1, df2])\n",
    "concatenated.sort_values(by=['IAGA_code', 'Timestamp'], inplace=True)\n",
    "\n",
    "concatenated.index.min(), concatenated.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"obsms\" />\n",
    "\n",
    "## Minute and second mean values\n",
    "\n",
    "[[TOP]](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files containing observatory minute and second mean values have CDF format. They can be downloade from:\n",
    "\n",
    "- ftp://ftp.nerc-murchison.ac.uk/geomag/Swarm/AUX_OBS/minute/\n",
    "- ftp://ftp.nerc-murchison.ac.uk/geomag/Swarm/AUX_OBS/second/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"obsms-read-cdf\" />\n",
    "\n",
    "### Read data from CDF files\n",
    "\n",
    "[[TOP]](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "# OPTIONAL - download data from the FTP server\n",
    "!wget -nv -nc -P ~/data/AUX_OBS/minute ftp://ftp.nerc-murchison.ac.uk/geomag/Swarm/AUX_OBS/minute/SW_OPER_AUX_OBSM2__201912*\n",
    "!wget -nv -nc -P ~/data/AUX_OBS/second ftp://ftp.nerc-murchison.ac.uk/geomag/Swarm/AUX_OBS/second/SW_OPER_AUX_OBSS2__201912*\n",
    "!find ~/data/AUX_OBS -name \"*.ZIP\" | while read f ; do unzip -u $f -d `dirname $f` ; done\n",
    "!find ~/data/AUX_OBS -name \"*.ZIP\" -delete\n",
    "!find ~/data/AUX_OBS -name \"*.HDR\" -delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select one of the AUX_OBSM2_ files (e.g. the first one):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = sorted(OBS_MINUTE_DIR.glob('SW_OPER_AUX_OBSM2_*.DBL'))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CDF file using `cdflib` (for more information on `cdflib`, see: https://github.com/MAVENSDC/cdflib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cdflib.CDF(file1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get info about the file as a Python dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cdf_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that measurements are stored as *zVariables*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cdf_info()['zVariables']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be retrieved via the `.varget()` method, e.g:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.varget('B_NEC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is returned as a `numpy.ndarray` object (for more information on `numpy.ndarray`, see: https://docs.scipy.org/doc/numpy/reference/arrays.ndarray.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable attributes can be retrieved using the `.varattsget()` method, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.varattsget('B_NEC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes are returned as a Python dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrieve the timestamps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.varget('Timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Timestamp` type is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.varget('Timestamp').dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestamps are represented as NumPy `float64` values. Why? Get info about `Timestamp` variable using the `.varinq()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.varinq('Timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned dictionary shows that the data type is *CDF_EPOCH* consising in a floating point value representing the number of milliseconds since 01-Jan-0000 00:00:00.000. It can be converted to a more readable format (list of strings) using the `cdflib.cdfepoch.encode()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = cdflib.cdfepoch.encode(data.varget('Timestamp'), iso_8601=True)\n",
    "\n",
    "ts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or to a numpy array of `numpy.datetime64` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.array(cdflib.cdfepoch.encode(data.varget('Timestamp'), iso_8601=True), dtype='datetime64')\n",
    "\n",
    "ts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be interested also in the CDF global attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.globalattsget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close the file when you have finished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUX_OBSS2_ data contains the same variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with closing(cdflib.cdfread.CDF(list(OBS_SECOND_DIR.glob('SW_OPER_AUX_OBSS2_*.DBL'))[0])) as data:\n",
    "    zvariables = data.cdf_info()['zVariables']\n",
    "\n",
    "zvariables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be represented as a `pandas.DataFrame` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with closing(cdflib.cdfread.CDF(file1)) as data:\n",
    "    ts = pd.DatetimeIndex(\n",
    "            cdflib.cdfepoch.encode(data.varget('Timestamp'), iso_8601=True),\n",
    "            name='Timestamp'\n",
    "        )\n",
    "    df1 = pd.DataFrame(\n",
    "        {\n",
    "            'IAGA_code': data.varget('IAGA_code')[:,0,0],\n",
    "            'Latitude': data.varget('Latitude'),\n",
    "            'Longitude': data.varget('Longitude'),\n",
    "            'Radius': data.varget('Radius'),\n",
    "            'B_N': data.varget('B_NEC')[:,0],\n",
    "            'B_E': data.varget('B_NEC')[:,1],\n",
    "            'B_C': data.varget('B_NEC')[:,2]\n",
    "        },\n",
    "        index=ts\n",
    "    )\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on `pandas.Dataframe` see: https://pandas.pydata.org/docs/reference/frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same result can be obtained with the `cdf_to_pandas()` function defined above (see [Settings and functions](#settings))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = cdf_to_pandas(file1)\n",
    "\n",
    "new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the two data frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.testing.assert_frame_equal(df1, new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: get minimum and maximum dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.index.min(), df1.index.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: get list of observatories (IAGA codes) stored in the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['IAGA_code'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: get list of observatories (IAGA codes) included in the following ranges of coordinates:\n",
    "- $30 \\leq Latitude \\leq 70$\n",
    "- $-10 \\leq Longitude \\leq 40$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[(df1['Latitude'] >= 30) & (df1['Latitude'] <= 70) & (df1['Longitude'] >= -10) & (df1['Longitude'] <= 40)]['IAGA_code'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do the same using the `.query()` method (see: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html#pandas.DataFrame.query):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.query('(30 <= Latitude <= 70) and (-10 <= Longitude <= 40)')['IAGA_code'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"obsms-multifiles\" />\n",
    "\n",
    "### Read data from multiple files\n",
    "\n",
    "[[TOP]](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas dataframes can be concatenated to represent data obtained from more than one file. E.g. read data from the next AUX_OBSM2_ file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = sorted(OBS_MINUTE_DIR.glob('SW_OPER_AUX_OBSM2_*.DBL'))[1]\n",
    "\n",
    "df2 = cdf_to_pandas(file2)\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two dataframes can be concatenated using the `pandas.concat()` function (for more information see: https://pandas.pydata.org/docs/reference/api/pandas.concat.html#pandas.concat):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated = pd.concat([df1, df2])\n",
    "concatenated.sort_values(by=['IAGA_code', 'Timestamp'], inplace=True)\n",
    "\n",
    "concatenated.index.min(), concatenated.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With AUX_OBSS2_ data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(OBS_SECOND_DIR.glob('SW_OPER_AUX_OBSS2_*.DBL'))[:2]\n",
    "\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated = pd.concat([cdf_to_pandas(file) for file in files])\n",
    "concatenated.sort_values(by=['IAGA_code', 'Timestamp'], inplace=True)\n",
    "\n",
    "concatenated.index.min(), concatenated.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
